**ctrl + f is fun !**

# 比较好的blog或者系统的教程

* http://blog.csdn.net/zouxy09
* http://blog.pluskid.org
* http://blog.csdn.net/baimafujinji
* http://www.cnblogs.com/en-heng
* http://ruder.io/
* http://mccormickml.com/tutorials/
* https://r2rt.com/
* https://blog.acolyer.org/
* http://www.crownpku.com
* http://lamda.nju.edu.cn/weixs/
* https://codesachin.wordpress.com
* **NN**：
    * https://mlnotebook.github.io/
    * https://www.gitbook.com/book/tigerneil/neural-networks-and-deep-learning-zh/details
    * http://neuralnetworksanddeeplearning.com/about.html
* **深度学习论文集**：
    * https://github.com/scofield7419/Deep-Learning-Papers-for-Fish
    * https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap

* stanford的NLPwithDL：http://web.stanford.edu/class/cs224n/syllabus.html
* 各种优化器介绍：http://ruder.io/optimizing-gradient-descent/

# 一些代码例子

* ACL2017的一篇中文分词文章的代码：https://github.com/jcyk/greedyCWS

## BILSTM_CRF
* https://github.com/chilynn/sequence-labeling
* https://github.com/scofield7419/sequence-labeling-BiLSTM-CRF
* https://mp.weixin.qq.com/s?__biz=MjM5ODIzNDQ3Mw==&mid=2649966433&idx=1&sn=be6c0e5485003d6f33804261df7c3ecf&chksm=beca376789bdbe71ef28c509776132d96e7e662be0adf0460cfd9963ad782b32d2d5787ff499&mpshare=1&scene=1&srcid=1122cZnCbEKZCCzf9LOSAyZ6&pass_ticket=lT4VaDjNiXiIPNmtxEJuioi434%2Bhm9W7at4S93hYP0U%3D#rd
* http://blog.csdn.net/appleml/article/details/70945298
* https://github.com/yanshao9798/tagger

# 一些导论

## NLP
* http://blog.csdn.net/sinat_26917383/article/details/55683599
* https://zhuanlan.zhihu.com/p/28126584
* https://zhuanlan.zhihu.com/p/24833012

### 分词
* http://blog.csdn.net/aiwuzhi12/article/details/54707695

# 一些概念或算法或模型的解释

## 信息熵
* https://zhuanlan.zhihu.com/p/26486223

## 条件熵
* https://zhuanlan.zhihu.com/p/26551798

## 梯度下降法
* http://blog.csdn.net/zouxy09/article/details/20319673

## 最大似然和EM
* http://blog.csdn.net/zouxy09/article/details/8537620

## SVM
* http://blog.csdn.net/zouxy09/article/details/17291543
* http://blog.pluskid.org/?page_id=683

### SMO
* https://www.cnblogs.com/jerrylead/archive/2011/03/18/1988419.html
* https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/smo-book.pdf
* http://blog.csdn.net/on2way/article/details/47730367
* http://blog.csdn.net/v_july_v/article/details/7624837

### KKT
在SVM中会提及，但不是SVM的专有概念
* http://www.onmyphd.com/?p=kkt.karush.kuhn.tucker

## HMM
* https://www.cnblogs.com/skyme/p/4651331.html

## CRF
* http://www.jianshu.com/p/55755fc649b1

* CRF++的解析，里面有对特征模版的解析：http://www.52nlp.cn/中文分词入门之字标注法4

* 分词实例：
    * http://www.52nlp.cn/初学者报道3-crf-中文分词解码过程理解
    * http://www.cnblogs.com/liufanping/p/4899842.html

* 这个比较难懂，下面是相关资料集合
    * http://www.52nlp.cn/条件随机场文献阅读指南
    * http://www.inference.org.uk/hmw26/crf/

## word2vec
* http://blog.csdn.net/mytestmy/article/details/26961315
* https://www.cnblogs.com/iloveai/p/word2vec.html
* https://www.tensorflow.org/tutorials/word2vec
* http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/

## RNN
* http://karpathy.github.io/2015/05/21/rnn-effectiveness/
* 在tensorflow中：https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767
* 上文第一篇的翻译：https://zhuanlan.zhihu.com/p/26646665
* https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html

### LSTM
* http://www.jianshu.com/p/9dc9f41f0b29
* http://colah.github.io/posts/2015-08-Understanding-LSTMs/

### seq2seq
* 基础seq2seq模型：https://zhuanlan.zhihu.com/p/27608348

## N-Gram
* http://blog.csdn.net/baimafujinji/article/details/51281816

## CNN
* http://blog.csdn.net/yunpiao123456/article/details/52437794
* http://www.cnblogs.com/fengfenggirl/p/cnn_implement.html

## L1、L2正则化
L1、L2以约束条件的形式给出比较好理解。SVM里面的那个松弛项，最后也是转化为约束条件，对SVM而言，超参数C越大，对离群点的容许越小，可以这么考虑，极端的，如果C为0，则无论离群多大，后面的惩罚项都是0，也就是对离群无限容许。数学上，感觉“惩罚项”和“松弛项”是差不多的。
* http://blog.csdn.net/jinping_shi/article/details/52433975
* http://blog.csdn.net/vividonly/article/details/50723852

## 降维相关

### SNE和t-SNE
* http://www.datakit.cn/blog/2017/02/05/t_sne_full.html
* https://distill.pub/2016/misread-tsne/

### PCA
* http://blog.jobbole.com/109015/

### SVD
* https://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html

### 线性判别分析LDA(Linear Discriminant Analysis)
* https://www.cnblogs.com/pinard/p/6244265.html

**↑↓这两个LDA是不同概念的缩写**

## LDA(Latent Dirichlet Allocation)主题模型
* http://blog.csdn.net/aws3217150/article/details/53840029

# 一些工具和库

## fasttext
* https://zhuanlan.zhihu.com/p/27699559

## Familia
* https://github.com/baidu/Familia/wiki

## TensorFlow

* 相关资源：
    * https://danijar.com/

## pytorch

* CrossEntropyLoss和NLLLoss：http://sshuair.com/2017/10/21/pytorch-loss/

## spotlight(推荐系统)
https://github.com/maciejkula/spotlight

* 包含传统的协同过滤方法
* 包含了DNN方法，这些方法都是把推荐问题当作序列预测处理，使用用户的历史信息，方法论文如下：
    * YouTube的pooling方法，这里实现的是一个简化版：https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf
    * LSTM：https://arxiv.org/pdf/1511.06939
    * causal convolution(空洞卷积)：https://arxiv.org/pdf/1609.03499

# 论文集（懒得下载）

## DCNN(IDCNN)
* MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS：https://arxiv.org/pdf/1511.07122.pdf
* Fast and Accurate Entity Recognition with Iterated Dilated Convolutions：https://arxiv.org/pdf/1702.02098.pdf

## Batch Normalization
* Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift：https://arxiv.org/pdf/1502.03167.pdf

## NER
* Character-Based LSTM-CRF with Radical-Level
Features for Chinese Named Entity Recognition：https://pdfs.semanticscholar.org/b944/5206f592423f0b2faf05f99de124ccc6aaa8.pdf

### 嵌套NER(nested entity 或 composite entity)

微软的luis、facebook的wit、谷歌的dialogflow都有composite entity。

* Nested Named Entity Recognition：https://nlp.stanford.edu/pubs/nested-ner.pdf
* 训练两个模型，一个是普通无nested，第二个是nested，第二个模型把无nested的NER信息作为特征：https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2014/2014_GermEval_Nested_Named_Entity_Recognition_with_Neural_Networks.pdf

## CWS
* Fast and Accurate Neural Word Segmentation for Chinese：https://arxiv.org/pdf/1704.07047.pdf
* Neural Word Segmentation Learning for Chinese：https://arxiv.org/pdf/1606.04300.pdf

# 语料资源

## 别人的索引
* https://github.com/crownpku/awesome-chinese-nlp#corpus-%E4%B8%AD%E6%96%87%E8%AF%AD%E6%96%99
* https://github.com/candlewill/Dialog_Corpus

## 某些下载页面
* ubuntu-corpus-1.0：http://dataset.cs.mcgill.ca/ubuntu-corpus-1.0/
* 病历NER：https://github.com/tangxiangru/CCKS2017
* http://111.200.194.212/cqp/
* http://www.lancaster.ac.uk/fass/projects/corpus/
* https://nlp.stanford.edu/links/statnlp.html